---
title: "Google trends models"
author: Christian Url
date: 'Last Compiled `r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    
    code_folding: show
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
               collapse = FALSE,
               comment = "",
               strip.white = TRUE,
               warning = FALSE,
               message = FALSE,
               cache = TRUE,
               out.width = "70%",
               fig.align = "center")

```

## load Packages
```{r}
library(data.table)
library(lubridate)
library(caret)
library(rai)
library(forecast)
library(parallel)
library(doParallel)
library(tidyverse)
```

## Paths
```{r}
datapath = "../data/"
trends_path = paste0(datapath, "googleTrendsAuto/")
ind_path = paste0(datapath, "indicators/")
```

## Functions
```{r}
scale2 <- function(x, na.rm = TRUE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
```


# Read data {.tabset .tabset-fade}
## Volatility Index {-}
```{r vol_ind}
vol_ind = read_delim(paste0(datapath,"country_volatility_index.csv")) %>%
  mutate(geo = str_split(Countries, " ", simplify = T)[,1], .before = 1,
         country = str_remove(Countries, ".*\\("), 
         country = str_extract(country, ".*(?=\\))"))

country_code_list = unlist(vol_ind$geo)
country_list = unlist(vol_ind$country)
country_code_list[country_list=="Greece"] <- "GR"
```

## Indicators {-}
Read indicator data and filter for valid countries. Countries are valid if they appear in the country volatility index.

```{r ind1}
list.files(ind_path)
ind_in = fread(paste0(ind_path,"tour_occ_nim_linear_all.csv"))

ind_t1 = ind_in[,-c(1:3)] %>% 
  as_tibble() %>%
  mutate(month_end = as_date(paste0(TIME_PERIOD,"-01")),.before=1) %>%
  filter(geo %in% vol_ind$geo)

ind_t1 %>% select(nace_r2) %>% distinct()
```

Build dataset:
```{r ind2}
df_ind = ind_t1 %>%
  filter(nace_r2 == "I551-I553" & unit=="NR") %>%
  group_by(geo, c_resid) %>%
  mutate(obs_value_std = scale2(OBS_VALUE), mean=mean(OBS_VALUE), sd = sd(OBS_VALUE)) %>%
  ungroup()

ind_wide = ind_t1 %>%
  filter(nace_r2 == "I551-I553" & unit=="NR") %>%
  mutate(obs_value_std = OBS_VALUE) %>%
  pivot_wider(id_cols = c(month_end, geo), names_from=c_resid, values_from = obs_value_std, names_prefix="resid_") %>%
  group_by(geo) %>%
  mutate(resid_DOM = coalesce(resid_DOM, resid_NAT),
         share_FOR = resid_FOR / resid_TOTAL,
         month = month(month_end),
         year = year(month_end),
         resid_DOM_STD = scale2(resid_DOM),
         resid_FOR_STD = scale2(resid_FOR),
         resid_TOTAL_STD = scale2(resid_TOTAL),
         ) %>%
  select(!resid_NAT) %>%
  ungroup() %>%
  arrange(geo,month_end)

ind_wide %>%
  filter(is.na(resid_DOM)) %>%
  distinct(geo)

ind_stats = ind_wide %>%
  group_by(geo) %>%
  summarise(resid_TOTAL_mean=mean(resid_TOTAL, na.rm = T), 
            resid_TOTAL_sd=sd(resid_TOTAL, na.rm = T), 
            resid_TOTAL_max=max(resid_TOTAL, na.rm = T), 
            resid_TOTAL_norm=max(abs(resid_TOTAL-mean(resid_TOTAL, na.rm = T)), na.rm=T)
            )

geo_minmax = ind_wide %>%
  group_by(geo) %>%
  summarise(min = min(year), max = max(year))

```

## Google Trends {-}
```{r trends}
list.files(trends_path)
goo = read_csv(paste0(trends_path, "trends_full.csv"))
trends_100 = goo %>%
  mutate(across(3:13, ~.x/100))
trends_norm = goo %>%
  mutate(across(3:13, scale2))
```

## Combine data {-}
```{r combine}
trends = ind_wide %>%
  select(month_end, geo, resid_TOTAL_STD) %>%
  rename(date = month_end, country_code = geo) %>%
  inner_join(trends_100, by=c("date", "country_code"))
```

# Modelling country_wise {.tabset .tabset-fade}
## Set up data {-}
```{r model data}
c_code = country_code_list[13]
ctry = country_list[13]

trends_cty = trends %>%
  filter(country_code == c_code)

trends_ts = trends_cty %>%
  select(!c(country_code,date)) %>%
  ts(start=c(2004,1), frequency=12)

theData = trends_cty[,-c(1:3)]
theResponse = trends_cty$resid_TOTAL_STD
```

## RAI
```{r}
mod_rai = rai(theData = theData, theResponse = theResponse)
summary(mod_rai$model)
```


## arimax {-}
```{r arimax}
X = as.matrix(theData)
mod1 = auto.arima(y = theResponse, max.order = 12, xreg = X,  max.D = 2)
mod1
```

## SVM {-}
```{r}
fitControl <- caret::trainControl(method = "repeatedcv",
                            number = 5, ## 5-fold CV...
                            repeats = 5)  ## repeated 5 times
mod_svn =caret::train(x=theData, y=theResponse, method="svmRadialSigma", trControl = fitControl, verbose=F)
mod_svn
```

## GBM {-}
```{r}
gbmGrid <-  expand.grid(interaction.depth = c(1:4), 
                        n.trees = c(50, 100, 150), 
                        shrinkage = 0.1,
                        n.minobsinnode = 5)
mod_gbm =caret::train(x=theData, y=theResponse, method="gbm", trControl = fitControl, tuneGrid=gbmGrid, verbose=F)
mod_gbm
```

## RF {-}
```{r}
mod_rf =caret::train(x=theData, y=theResponse, method="rf", trControl = fitControl, verbose=F)
mod_rf
```

## NN? {-}
```{r}

```

