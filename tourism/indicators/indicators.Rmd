---
title: "Tourism indicator data"
author: Christian Url
date: 'Last Compiled `r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    
    code_folding: show
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
               collapse = FALSE,
               comment = "",
               strip.white = TRUE,
               warning = FALSE,
               message = FALSE,
               cache = FALSE,
               out.width = "70%",
               fig.align = "center")

```


## load Packages
```{r}
library(data.table)
library(tidyverse)
library(lubridate)
library(rai)
library(caret)
```


# Load Data

```{r}
datapath = "../data/"
ind_path = paste0(datapath, "indicators/")
list.files(ind_path)
ind_in = fread(paste0(ind_path,"tour_occ_nim_linear_all.csv"))

ind_t1 = ind_in[,-c(1:3)] %>% 
  as_tibble() %>%
  mutate(month_end = as_date(paste0(TIME_PERIOD,"-01")),.before=1)

ind_t1 %>% select(nace_r2) %>% distinct()

## Scale
scale2 <- function(x, na.rm = TRUE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)

# ind_de= ind_t1 %>% 
#   filter(geo == "DE" & nace_r2 == "I551-I553" & unit=="NR" & c_resid=="TOTAL") %>%
#   mutate(obs_value_std = scale2(OBS_VALUE),
#          obs_value_norm = (OBS_VALUE-mean(OBS_VALUE))/max(abs(OBS_VALUE-mean(OBS_VALUE))),
#          obs_value_max = OBS_VALUE/max(OBS_VALUE)
#          )
# 
# ind_stats = ind_de %>%
#   summarise(mean=mean(OBS_VALUE), 
#             sd=sd(OBS_VALUE), 
#             max=max(OBS_VALUE), 
#             norm=max(abs(OBS_VALUE-mean(OBS_VALUE)))
#             )
```

# Calculate share of foreign nights

Build dataset:
```{r}
df_ind = ind_t1 %>%
  filter(nace_r2 == "I551-I553" & unit=="NR") %>%
  group_by(geo, c_resid) %>%
  mutate(obs_value_std = scale2(OBS_VALUE), mean=mean(OBS_VALUE), sd = sd(OBS_VALUE)) %>%
  ungroup()

ind_wide = ind_t1 %>%
  filter(nace_r2 == "I551-I553" & unit=="NR") %>%
  mutate(obs_value_std = OBS_VALUE) %>%
  pivot_wider(id_cols = c(month_end, geo), names_from=c_resid, values_from = obs_value_std, names_prefix="resid_") %>%
  group_by(geo) %>%
  mutate(resid_DOM = coalesce(resid_DOM, resid_NAT),
         share_FOR = resid_FOR / resid_TOTAL,
         month = month(month_end),
         year = year(month_end),
         resid_DOM_STD = scale2(resid_DOM),
         resid_FOR_STD = scale2(resid_FOR),
         resid_TOTAL_STD = scale2(resid_TOTAL),
         ) %>%
  select(!resid_NAT) %>%
  ungroup()

ind_wide %>%
  filter(is.na(resid_DOM)) %>%
  distinct(geo)

ind_stats = ind_wide %>%
  group_by(geo) %>%
  summarise(resid_TOTAL_mean=mean(resid_TOTAL, na.rm = T), 
            resid_TOTAL_sd=sd(resid_TOTAL, na.rm = T), 
            resid_TOTAL_max=max(resid_TOTAL, na.rm = T), 
            resid_TOTAL_norm=max(abs(resid_TOTAL-mean(resid_TOTAL, na.rm = T)), na.rm=T)
            )

geo_minmax = ind_wide %>%
  group_by(geo) %>%
  summarise(min = min(year), max = max(year))

print(geo_minmax, n=nrow(geo_minmax))
```

Plot of 5 years for 6 countries:
```{r}
country_filter = c("AT","DE","IT","ES","EL","PT", "FR", "CY", "HR")
ind_wide %>%
  filter(geo %in% country_filter & year >= 2016) %>%
  ggplot(aes(x = month, y=share_FOR,group = interaction(factor(year),geo), color = factor(year))) + 
  geom_line() + 
  facet_wrap(~geo)
```

Total number of foreign
```{r}
ind_wide %>%
  filter(geo %in% country_filter & year >= 2016) %>%
  ggplot(aes(x = month, y=resid_FOR,group = interaction(factor(year),geo), color = factor(year))) + 
  geom_line() + 
  facet_wrap(~geo)

```

Total number of tourism nights spend:
```{r}
ind_wide %>%
  filter(geo %in% country_filter & year >= 2016) %>%
  ggplot(aes(x = month, y=resid_TOTAL,group = interaction(factor(year),geo), color = factor(year))) + 
  geom_line() + 
  facet_wrap(~geo)
```

For an trend estimate, we need to remove the years 2020-21. Due to covid, these are not representatieve . What is more,
we can use the years 2016-2019 as quite good predictors for 2022. BUT: how do we include these into the acutal forecasts? Time Series models with period = 12. 

Solution: Predict values for every observation and use these predictions as regressors.

# Time series modeling 

## libs
```{r}
library(forecast)
library(parallel)
library(doParallel)
```


## Using arima for predicting September 2022

```{r multicore, cache=TRUE}
cl = detectCores()-1
registerDoParallel(cl)

geo_filter = geo_minmax %>%
  filter(max == 2022) %>% 
  .$geo 

res_list = foreach(i = 1:length(geo_filter), .packages=c("tidyverse","forecast")) %dopar% {
  ind_stats_act = ind_stats %>%
    filter(geo == geo_filter[i])
  
  ts_def = ind_wide %>%
    filter(geo == geo_filter[i]) %>%
    summarise(mon = min(month), year = min(year))

  ind_ts = ind_wide %>%
    filter(geo == geo_filter[i]) %>%
    select(resid_TOTAL_STD) %>%
    ts(frequency = 12, start = c(ts_def$year, ts_def$mon))

  mod = auto.arima(ind_ts, max.d = 4, max.D = 4, max.order = 12, max.p = 12, max.q = 12)
  pred = forecast(mod, h = 4)

  yhat = pred$mean * ind_stats_act$resid_TOTAL_sd + ind_stats_act$resid_TOTAL_mean
  
  yhat_df = tibble(month_end = zoo::as.Date(pred$mean),geo=geo_filter[i], yhat = yhat)
}

res_df = do.call(bind_rows, res_list)

stopImplicitCluster()

res_df

write_csv(res_df, file="arima_forecasts.csv")
```


## rolling window forecasting - no eval
Use 10 years of data for first estimate, then monthly rolling window - but this is absolutely not necessary as we cannot use it in the analysis!
```{r, eval = F}
geo_filter = geo_minmax %>%
  filter(min <= 2011 & max == 2022) %>% 
  .$geo 

res_list = foreach(i = 1:length(geo_filter), .packages=c("tidyverse","forecast")) %dopar% {
  ind_stats_act = ind_stats %>%
    filter(geo == geo_filter[i])
  
  ts_def = ind_wide %>%
    filter(geo == geo_filter[i]) %>%
    summarise(mon = min(month), year = min(year))

  ind_ts = ind_wide %>%
    filter(geo == geo_filter[i]) %>%
    select(resid_TOTAL_STD) %>%
    ts(frequency = 12, start = c(ts_def$year, ts_def$mon))

  mod = auto.arima(ind_ts, max.d = 4, max.D = 4, max.order = 12, max.p = 12, max.q = 12)
  pred = predict(mod, n.ahead = 4)

  yhat = pred$pred * ind_stats_act$resid_TOTAL_sd + ind_stats_act$resid_TOTAL_mean
  
  yhat_df = tibble(month_end = zoo::as.Date(pred$pred), yhat = yhat)
  
  yhat_df2 = yhat_df %>% 
    add_column(
      tibble( geo = geo_filter[i],
              p=arimaorder(mod)[1],
              d=arimaorder(mod)[2],
              q=arimaorder(mod)[3],
              P=arimaorder(mod)[4],
              D=arimaorder(mod)[5],
              Q=arimaorder(mod)[6],
              FR = arimaorder(mod)[7]))

}

res_df = do.call(bind_rows, res_list)

stopImplicitCluster()
```

