---
title: "Tourism indicator data"
author: Christian Url
date: 'Last Compiled `r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    
    code_folding: show
    highlight: tango
    number_sections: yes
    theme: cosmo
    toc: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
               collapse = FALSE,
               comment = "",
               strip.white = TRUE,
               warning = FALSE,
               message = FALSE,
               cache = TRUE,
               out.width = "70%",
               fig.align = "center")

```


## load Packages
```{r}
library(data.table)
library(tidyverse)
library(lubridate)
library(rai)
library(caret)
```


# Load Data

## Volatility Index
```{r}
datapath = "../data/"
vol_ind = read_delim(paste0(datapath,"country_volatility_index.csv")) %>%
  mutate(geo = str_split(Countries, " ", simplify = T)[,1], .before = 1)
```

## Indicators

Read indicator data and filter for valid countries. Countries are valid if they appear in the country volatility index.

```{r}
datapath = "../data/"
ind_path = paste0(datapath, "indicators/")
list.files(ind_path)
ind_in = fread(paste0(ind_path,"tour_occ_nim_linear_all.csv"))

ind_t1 = ind_in[,-c(1:3)] %>% 
  as_tibble() %>%
  mutate(month_end = as_date(paste0(TIME_PERIOD,"-01")),.before=1) %>%
  filter(geo %in% vol_ind$geo)

ind_t1 %>% select(nace_r2) %>% distinct()

## Scale
scale2 <- function(x, na.rm = TRUE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)

# ind_de= ind_t1 %>% 
#   filter(geo == "DE" & nace_r2 == "I551-I553" & unit=="NR" & c_resid=="TOTAL") %>%
#   mutate(obs_value_std = scale2(OBS_VALUE),
#          obs_value_norm = (OBS_VALUE-mean(OBS_VALUE))/max(abs(OBS_VALUE-mean(OBS_VALUE))),
#          obs_value_max = OBS_VALUE/max(OBS_VALUE)
#          )
# 
# ind_stats = ind_de %>%
#   summarise(mean=mean(OBS_VALUE), 
#             sd=sd(OBS_VALUE), 
#             max=max(OBS_VALUE), 
#             norm=max(abs(OBS_VALUE-mean(OBS_VALUE)))
#             )
```

# Calculate share of foreign nights

Build dataset:
```{r}
df_ind = ind_t1 %>%
  filter(nace_r2 == "I551-I553" & unit=="NR") %>%
  group_by(geo, c_resid) %>%
  mutate(obs_value_std = scale2(OBS_VALUE), mean=mean(OBS_VALUE), sd = sd(OBS_VALUE)) %>%
  ungroup()

ind_wide = ind_t1 %>%
  filter(nace_r2 == "I551-I553" & unit=="NR") %>%
  mutate(obs_value_std = OBS_VALUE) %>%
  pivot_wider(id_cols = c(month_end, geo), names_from=c_resid, values_from = obs_value_std, names_prefix="resid_") %>%
  group_by(geo) %>%
  mutate(resid_DOM = coalesce(resid_DOM, resid_NAT),
         share_FOR = resid_FOR / resid_TOTAL,
         month = month(month_end),
         year = year(month_end),
         resid_DOM_STD = scale2(resid_DOM),
         resid_FOR_STD = scale2(resid_FOR),
         resid_TOTAL_STD = scale2(resid_TOTAL),
         ) %>%
  select(!resid_NAT) %>%
  ungroup() %>%
  arrange(geo,month_end)

ind_wide %>%
  filter(is.na(resid_DOM)) %>%
  distinct(geo)

ind_stats = ind_wide %>%
  group_by(geo) %>%
  summarise(resid_TOTAL_mean=mean(resid_TOTAL, na.rm = T), 
            resid_TOTAL_sd=sd(resid_TOTAL, na.rm = T), 
            resid_TOTAL_max=max(resid_TOTAL, na.rm = T), 
            resid_TOTAL_norm=max(abs(resid_TOTAL-mean(resid_TOTAL, na.rm = T)), na.rm=T)
            )

geo_minmax = ind_wide %>%
  group_by(geo) %>%
  summarise(min = min(year), max = max(year))

print(geo_minmax, n=nrow(geo_minmax))
```

Plot of 5 years for all countries:
```{r plt_share, cache = T}
ind_wide %>%
  filter(year >= 2016) %>%
  ggplot(aes(x = month, y=share_FOR,group = interaction(factor(year),geo), color = factor(year))) + 
  geom_line() + 
  facet_wrap(~geo)
```

Total number of foreign
```{r plt_for, cache = T}
ind_wide %>%
  filter(year >= 2016) %>%
  ggplot(aes(x = month, y=resid_FOR,group = interaction(factor(year),geo), color = factor(year))) + 
  geom_line() + 
  facet_wrap(~geo)

```

Total number of tourism nights spend:
```{r plt_tot, cache = T}
ind_wide %>%
  filter(year >= 2016) %>%
  ggplot(aes(x = month, y=resid_TOTAL,group = interaction(factor(year),geo), color = factor(year))) + 
  geom_line() + 
  facet_wrap(~geo)
```

For an trend estimate, we need to remove the years 2020-21. Due to covid, these are not representatieve . What is more,
we can use the years 2016-2019 as quite good predictors for 2022. BUT: how do we include these into the acutal forecasts? Time Series models with period = 12. 

Solution: Predict values for every observation and use these predictions as regressors.

# Time series modeling 

## libs
```{r}
library(forecast)
library(parallel)
library(doParallel)
```


## Using arima for predicting September 2022

```{r multicore}
cl = detectCores()-1
registerDoParallel(cl)

geo_filter = geo_minmax %>%
  filter(max == 2022) %>% 
  .$geo 

res_list = foreach(i = 1:length(geo_filter), .packages=c("tidyverse","forecast"), .multicombine = T, .combine = rbind) %dopar% {
  ind_stats_act = ind_stats %>%
    filter(geo == geo_filter[i])
  
  ts_def = ind_wide %>%
    filter(geo == geo_filter[i]) %>%
    summarise(mon = min(month), year = min(year))

  ind_ts = ind_wide %>%
    filter(geo == geo_filter[i]) %>%
    select(resid_TOTAL_STD) %>%
    ts(frequency = 12, start = c(ts_def$year, ts_def$mon))

  mod = auto.arima(ind_ts, max.d = 4, max.D = 4, max.order = 24, max.p = 12, max.q = 12)
  pred = forecast(mod, h = 4)

  yhat = pred$mean * ind_stats_act$resid_TOTAL_sd + ind_stats_act$resid_TOTAL_mean
  coefs = as.data.frame(coef(mod)) %>% 
    rownames_to_column(var = "coef") %>%
    rename(val = `coef(mod)`) %>%
    pivot_wider(names_from = coef, values_from = val) %>%
    add_column(geo = geo_filter[i], .before = 1) %>%
    add_column(sigma = mod$sigma2)
  
  arima_order = as.data.frame(arimaorder(mod)) %>% 
    rownames_to_column(var = "coef") %>%
    rename(val = `arimaorder(mod)`) %>%
    pivot_wider(names_from = coef, values_from = val) %>%
    add_column(geo = geo_filter[i], .before = 1)
    
  
  yhat_list = list(tibble(month_end = zoo::as.Date(pred$mean),geo=geo_filter[i], yhat = yhat, bic = mod$bic, 
                   rmse = forecast::accuracy(mod)[2], mae = forecast::accuracy(mod)[3], acf = forecast::accuracy(mod)[7]),
                   coefs,
                   arima_order)
}
res_df = do.call(bind_rows, res_list[,1])
coefs_df = do.call(bind_rows, res_list[,2])
arima_order_df = do.call(bind_rows, res_list[,3])

stopImplicitCluster()

res_df

write_csv(res_df, file="arima_forecasts.csv")
write_csv(coefs_df, file="arima_forecasts_coefs.csv")
write_csv(arima_order_df, file="arima_forecasts_order.csv")
```

overview over last forecast date:

```{r}
overview = res_df %>%
  group_by(geo) %>%
  summarise(min_date = min(month_end), max_date = max(month_end), bic = min(bic), rmse = min(rmse), mae = min(mae), acf = min(acf))

print(overview, n = nrow(overview))

print(filter(overview, min_date >= as_date("2022-07-01")), n = nrow(filter(overview, min_date >= as_date("2022-07-01"))))
print(arima_order_df, n = nrow(arima_order_df))
coefs_df
```

coefficients: 
```{r, results='asis'}
print(xtable::xtable(coefs_df), type="html")
```

*September forecasts:* 
```{r, results='asis'}
sept = res_df %>%
  filter(month_end == as_date("2022-09-01"))

print(xtable::xtable(sept), type="html")
```



## Arimax - use google trends data in arima model

```{r}
goo_path = paste0(datapath, "googleTrends/")
series = "Germany1_full.csv"
input = paste0(goo_path, series)
# in_list =input %>% map(~fread(., skip=2))
# in_list = map(in_list, as_tibble)
# df = reduce(.x = in_list, .f = full_join)

df_mon = fread(input, skip = 2) %>% as_tibble()

div_100 = function(x) (x/100)
df_mon = df_mon %>% mutate(across(.cols = 2:6, scale2))

df_mon_cl = df_mon %>% 
   rename(tour_de=`Tourismus: (Deutschland)`,
          nights_de=`Übernachtungen: (Deutschland)`,
          lastm_de=`last minute: (Deutschland)`, 
          allincl_de=`All inclusive: (Deutschland)`, 
          goofl_de=`Google Flüge: (Deutschland)`
          ) %>%
  mutate(month_end = as_date(paste0(Monat,"-01")),.before=1) %>%
  select(!c(Monat,goofl_de))

ind_wide2 = ind_wide %>%
  left_join(df_mon_cl, by="month_end") %>%
  filter(!is.na(tour_de))

ind_stats2 = ind_wide2 %>%
  group_by(geo) %>%
  summarise(resid_TOTAL_mean=mean(resid_TOTAL, na.rm = T), 
            resid_TOTAL_sd=sd(resid_TOTAL, na.rm = T), 
            resid_TOTAL_max=max(resid_TOTAL, na.rm = T), 
            resid_TOTAL_norm=max(abs(resid_TOTAL-mean(resid_TOTAL, na.rm = T)), na.rm=T)
            )
geo_minmax2 = ind_wide2 %>%
  group_by(geo) %>%
  summarise(min = min(year), max = max(year))

geo_filter = geo_minmax2 %>%
  filter(max == 2022) %>% 
  .$geo
```


```{r arimax}
cl = detectCores()-1
registerDoParallel(cl)

res_list2 = foreach(i = 1:length(geo_filter), .packages=c("tidyverse","forecast"), .multicombine = T, .combine = rbind) %dopar% {

  x_reg = ind_wide2 %>%
    filter(geo == geo_filter[i]) %>%
    .[,12:15] %>%
    as.matrix()
  
  ind_stats_act = ind_stats2 %>%
      filter(geo == geo_filter[i])
    
  ts_def = ind_wide2 %>%
      filter(geo == geo_filter[i]) %>%
      summarise(mon = min(month), year = min(year))
  
  ind_ts = ind_wide2 %>%
      filter(geo == geo_filter[i]) %>%
      select(resid_TOTAL_STD) %>%
      ts(frequency = 12, start = c(ts_def$year, ts_def$mon))
  
  mod = auto.arima(ind_ts, max.d = 4, max.D = 4, max.order = 24, max.p = 12, max.q = 12, xreg=x_reg)
  
  # yhat = ... 
  # yhat_df = ...
  
  coefs = as.data.frame(coef(mod)) %>% 
    rownames_to_column(var = "coef") %>%
    rename(val = `coef(mod)`) %>%
    pivot_wider(names_from = coef, values_from = val) %>%
    add_column(geo = geo_filter[i], .before = 1) %>%
    add_column(sigma = mod$sigma2)
  
  arima_order = as.data.frame(arimaorder(mod)) %>% 
    rownames_to_column(var = "coef") %>%
    rename(val = `arimaorder(mod)`) %>%
    pivot_wider(names_from = coef, values_from = val) %>%
    add_column(geo = geo_filter[i], .before = 1)
    
  
  yhat_list = list(tibble(geo=geo_filter[i], bic = mod$bic, 
                   rmse = forecast::accuracy(mod)[2], mae = forecast::accuracy(mod)[3], acf = forecast::accuracy(mod)[7]),
                   coefs,
                   arima_order)
}
res_df2 = do.call(bind_rows, res_list2[,1])
coefs_df2 = do.call(bind_rows, res_list2[,2])
arima_order_df2 = do.call(bind_rows, res_list2[,3])

stopImplicitCluster()

print(arima_order_df2, n = nrow(arima_order_df2))


print(res_df2, n=nrow(res_df2))

 write_csv(res_df2, file="arima_forecasts2.csv")
 write_csv(coefs_df2, file="arima_forecasts_coefs2.csv")
 write_csv(arima_order_df2, file="arima_forecasts_order2.csv")
```


```{r, results='asis'}
print(xtable::xtable(coefs_df2), type="html")
```

